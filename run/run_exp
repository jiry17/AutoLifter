#!/usr/bin/env python3

import os
import json
import math
import argparse
from tqdm import tqdm

def load_json(path, is_strict = False):
	if not os.path.exists(path):
		assert not is_strict
		return {}
	with open(path, "r") as inp:
		info = json.load(inp)
	return info

def save_cache(path, info):
	with open(path, "w") as oup:
		json.dump(info, oup, indent = 4)

source_path = "SOURCEPATH/"
exe_path = os.path.join(source_path, "build/main")
run_dir = os.path.join(source_path, "run")
cache_dir = os.path.join(run_dir, "result_cache")
time_cache_dir = os.path.join(run_dir, "time_result_cache")

def get_file(paths):
	path = ""
	for name in paths[:-1]:
		path = os.path.join(path, name)
		if not os.path.exists(path): os.mkdir(path)
	final_path = os.path.join(run_dir, path, paths[-1])
	if os.path.exists(final_path): os.remove(final_path)
	return final_path

def extractResult(oup_file):
	if not os.path.exists(oup_file):
		return {"status": "fail"}
	with open(oup_file, "r") as inp:
		lines = inp.readlines()
	if "Success" not in "".join(lines):
		return {"status": "fail"}

	def extractTotalTime(lines):
		for line in lines:
			if "Total time cost" in line:
				l, r = line.split(": ")
				if r[-1] == '\n': r = r[:-1]
				return float(r)
		return None

	def extractLiftNum(lines):
		info = []
		for line in lines:
			if line[0] == '|':
				if line[-1] == '\n': line = line[:-1]
				info.append(line)
		assert len(info) == 2
		info[0] = info[0].split('|')
		info[1] = info[1].split('|')
		assert len(info[0]) == len(info[1])
		for a, b in zip(info[0], info[1]):
			if "#lifting" in a: return int(b.strip())
		return None

	total_time = extractTotalTime(lines)
	if total_time is None: return {"status": "fail"}
	lift_num = extractLiftNum(lines)
	return {"status": "success", "time": total_time, "lift_num": lift_num}


def execute(solver_name, problem_name, benchmark):
	oup_file = get_file(["oup", solver_name, problem_name, benchmark])
	runnable_file = get_file(["runnable", solver_name, problem_name, benchmark])
	command = ['ulimit -v ' + str(memory_limit) + ';' + "timeout " + str(time_out) + " " + exe_path,
			   "--solver=\"" + solver_name + "\"",
			   "--problem=\"" + problem_name + "\"", "--name=\"" + benchmark + "\"",
			   "--oup=\"" + oup_file + "\"",
			   "--runnable=\"" + runnable_file + "\"", ">/dev/null", "2>/dev/null"]
	command = " ".join(command)
	os.system(command)
	res = extractResult(oup_file)
	return res

def run(solver_name):
	print("running", solver_name)
	benchmark_info = load_json("benchmark.json", True)
	benchmarks = []
	for problem, track in benchmark_info.items():
		for benchmark in track:
			benchmarks.append((problem, benchmark))
	cache_path = os.path.join(cache_dir, solver_name + ".json")
	cache = load_json(cache_path)
	count = 0
	for problem, benchmark in tqdm(benchmarks):
		if problem not in cache: cache[problem] = {}
		if benchmark in cache[problem]: continue
		count += 1
		cache[problem][benchmark] = execute(solver_name, problem, benchmark)
		if count % 10 == 0: save_cache(cache_path, cache)
	save_cache(cache_path, cache)
	return cache

def print_result(title, result, size = 6):
	def get_width(val):
		if type(val) == float: return len("%.3f" % val)
		return len(str(val))

	size_list = [size] * 100
	contents = []
	col_num = 0
	for row in result:
		pre, new_row = 0, []
		for content in row:
			val, width = content if type(content) == tuple else (content, 1)
			new_row.append((val, pre, pre + width))
			if width == 1: size_list[pre] = max(size_list[pre], get_width(val))
			pre += width
		contents.append(new_row)
		col_num = max(col_num, pre)
	title_width = sum(size_list[:col_num]) + col_num * 3 + 1
	print()
	print(title.center(title_width, " "))
	for row in contents:
		for val, l, r in row:
			width = sum(size_list[l: r]) + (r - l - 1) * 3
			if type(val) == int:
				val = str(val)
			elif type(val) == float:
				val = "%.3f" % val
			val = val.center(width, " ")
			print("| %s " % val, end = "")
		print("|")
	print()

def is_cared_track(name, expected):
	return name == expected or expected == "total"

def is_success(res):
	return "status" not in res or str(res["status"]) in ["success", "true", "True"]

def get_solved(cache, cared_track):
	num = 0
	for track_name, track_res in cache.items():
		if not is_cared_track(track_name, cared_track): continue
		for benchmark, benchmark_res in track_res.items():
			if is_success(benchmark_res): num += 1
	return num

def _divide(a, b):
	return "N/A" if b == 0 else a / b

def get_shared_average_time(base_cache, our_cache, cared_track):
	num, base_time, our_time = 0, 0, 0
	for track_name in base_cache:
		if not is_cared_track(track_name, cared_track): continue
		assert track_name in our_cache
		for benchmark in base_cache[track_name]:
			assert benchmark in our_cache[track_name]
			base_res, our_res = base_cache[track_name][benchmark], our_cache[track_name][benchmark]
			if is_success(base_res) and is_success(our_res):
				num += 1
				base_time += base_res["time"]
				our_time += our_res["time"]

	return num, _divide(base_time, num), _divide(our_time, num)

def add_times(ratio):
	return "*%.3f" % ratio

def add_percent(ratio):
	return "%.2f" % (ratio * 100) + r"%"

def get_res_time_ratio(cache, cared_track):
	def _average(ratios):
		if len(ratios) == 0: return "N/A"
		w = 0
		for ratio in ratios: w += math.log(ratio)
		w /= len(ratios)
		return math.exp(w)

	ratio_list = []
	for track_name, track_res in cache.items():
		if not is_cared_track(track_name, cared_track): continue
		for benchmark_res in track_res.values():
			if is_success(benchmark_res):
				if min(benchmark_res["baseline"], benchmark_res["autolifter"]) < 10 ** -5: continue
				ratio_list.append(benchmark_res["baseline"] / benchmark_res["autolifter"])
	return len(ratio_list), add_times(_average(ratio_list))

def get_full_compare(baseline, cared_track):
	our_cache = load_json(os.path.join(cache_dir, "AutoLifter.json"), True)
	base_cache = load_json(os.path.join(cache_dir, baseline + ".json"), True)
	solved_num = get_solved(base_cache, cared_track)
	_, base_time, our_time = get_shared_average_time(base_cache, our_cache, cared_track)
	if baseline == "AutoLifter":
		return solved_num, base_time, our_time, "*1.000"
	time_cache = load_json(os.path.join(time_cache_dir, "AutoLifter-" + baseline + ".json"), True)
	_, res_time_ratio = get_res_time_ratio(time_cache, cared_track)
	return solved_num, base_time, our_time, res_time_ratio


def print_compare_table(title, baselines):
	parts = [["dac", "single-pass"], ["longest-segment", "segment-tree"], ["total"]]
	rows = [[(" ", 9)]]
	for part in parts:
		row1 = ["Problem"] + [(name, 4) for name in part]
		row2 = ["Solver"] + ["#Solved", "Time[Base]", "Time[Ours]", "Time[Res]"] * len(part)
		row3 = ["AutoLifter"]
		for name in part:
			solved, base_time, our_time, res_time = get_full_compare("AutoLifter", name)
			row3 += [solved, (base_time, 2), res_time]
		rows += [row1, row2, row3]
		for base in baselines:
			row = [base]
			for name in part: row += get_full_compare(base, name)
			rows.append(row)
		rows.append([(" ", 9)])
	print_result(title, rows[:-1])

def rq1():
	print("=" * 20 + " RQ1 " + "=" * 20)
	run("AutoLifter")
	run("ESolver")
	run("Relish")
	print_compare_table("Table 5: The results of comparing AutoLifter with Enum and Relish", ["ESolver", "Relish"])

def rq2():
	print("=" * 20 + " RQ2 " + "=" * 20)
	run("AutoLifter")
	row1 = ["Solver", "#Solved[Base]", "#Solved[Ours]", "Time[Base]", "Time[Ours]", "Time[Res]", "#Aux[SP]"]
	row2 = ["Parsynt17"]
	p17_cache = load_json(os.path.join(cache_dir, "Parsynt17.json"), True)
	our_cache = load_json(os.path.join(cache_dir, "AutoLifter.json"), True)
	p17_num, our_num, p17_aux, p17_given = 0, 0, 0, 0
	for track in p17_cache:
		assert track in our_cache
		for benchmark_name in p17_cache[track]:
			assert benchmark_name in our_cache[track]
			p17_res, our_res = p17_cache[track][benchmark_name], our_cache[track][benchmark_name]
			if is_success(p17_res):
				p17_num += 1
				p17_aux += p17_res["lift_num"]
				if "given_num" in p17_res: p17_given += p17_res["given_num"]
			if is_success(our_res): our_num += 1
	row2 += [p17_num, our_num]
	_, p17_cost, our_cost = get_shared_average_time(p17_cache, our_cache, "total")
	row2 += [p17_cost, our_cost, "N/A", add_percent(p17_given / (p17_given + p17_aux))]

	row3 = ["Parsynt21"]
	p21_cache = load_json(os.path.join(cache_dir, "Parsynt21.json"), True)
	time_ratio_cache = load_json(os.path.join(time_cache_dir, "AutoLifter-Parsynt21.json"), True)
	p21_num, our_num, p21_aux, p21_given = 0, 0, 0, 0
	for track in p21_cache:
		assert track in our_cache
		for benchmark_name in p21_cache[track]:
			assert benchmark_name in our_cache[track]
			p21_res, our_res = p21_cache[track][benchmark_name], our_cache[track][benchmark_name]
			if is_success(p21_res):
				p21_num += 1
				p21_aux += p21_res["lift_num"]
				if "given_num" in p21_res: p21_given += p21_res["given_num"]
			if is_success(our_res): our_num += 1
	row3 += [p21_num, our_num]
	_, p21_cost, our_cost = get_shared_average_time(p21_cache, our_cache, "total")
	_, time_ratio = get_res_time_ratio(time_ratio_cache, "total")
	row3 += [p21_cost, our_cost, time_ratio, add_percent(p21_given / (p21_given + p21_aux))]

	print_result("Table 6. The results of comparing AutoLifter with Parsynt.", [row1, row2, row3])

def rq3():
	print("=" * 20 + " RQ3 " + "=" * 20)
	run("AutoLifter")
	rows = [["Solver", "#Solved", "Time[Base]", "Time[Ours]", "Time[Res]"]]
	solved, base_time, our_time, res_time = get_full_compare("AutoLifter", "single-pass")
	rows.append(["AutoLifter", solved, (base_time, 2), res_time])
	for name in ["DPASyn", "DPASyn_plus"]:
		solved, base_time, our_time, res_time = get_full_compare(name, "single-pass")
		rows.append([name, solved, base_time, our_time, res_time])
	rows[2][0], rows[3][0] = "DPASyn=", "DPASyn+"
	print_result("Section 8.4. The results of comparing AutoLifter with DPASyn", rows)


def rq4():
	print("=" * 20 + " RQ4 " + "=" * 20)
	run("AutoLifter")
	run("OE")
	print_compare_table("Table 7. The results of comparing AutoLifter with AutoLifter[OE].", ["OE"])

def get_bk_name(name):
	index = 1
	while True:
		bk_name = name + "_bk%d" % index + ".json"
		if not os.path.exists(os.path.join(cache_dir, bk_name)):
			return bk_name
		index += 1

def clear_cache():
	for cache_file in os.listdir(cache_dir):
		if cache_file[-5:] == ".json" and cache_file[:-5] in ["AutoLifter", "ESolver", "Relish", "OE"]:
			bk_name = get_bk_name(cache_file[:-5])
			os.rename(os.path.join(cache_dir, cache_file), os.path.join(cache_dir, bk_name))

def parse_args():
	parser = argparse.ArgumentParser()
	parser.add_argument('-exp', '--exp', type=int, choices=[1 ,2, 3, 4], default=None)
	parser.add_argument('--restart', dest="restart", action="store_true")
	parser.set_defaults(restart=False)
	parser.add_argument('-t', '--time-limit', type=int, default=300)
	parser.add_argument('-m', '--memory-limit', type=int, default=8)
	return parser.parse_args()


if __name__ == "__main__":
	arg = parse_args()

	time_out = arg.time_limit
	memory_limit = arg.memory_limit * 1024 * 1024
	if arg.restart: clear_cache()
	table_list = range(1, 5) if arg.exp is None else [arg.exp]
	if 1 in table_list: rq1()
	if 2 in table_list: rq2()
	if 3 in table_list: rq3()
	if 4 in table_list: rq4()